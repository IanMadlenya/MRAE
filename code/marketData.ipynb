{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning process\n",
    "Let's define a market which:\n",
    "* Takes Bloomberg input with multiple stocks\n",
    "* Sets up a dictionanry of dataframes including each stock\n",
    "* Handles missing values:\n",
    "    * Remove stocks that start after 20040101\n",
    "    * Remove holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bokeh.charts import Bar, output_file, output_notebook, show, reset_output\n",
    "from collections import OrderedDict\n",
    "from datetime import datetime\n",
    "from pandas import Series, DataFrame\n",
    "from pandas.tseries.offsets import BDay\n",
    "\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas.io.data\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Market definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Market:\n",
    "    def __init__(self, file='../donnees/raw/market.csv'):\n",
    "        self.marketFile=file\n",
    "        self.stockNames = self.getStockNames()\n",
    "        self.stocks = self.getStocks()\n",
    "        \n",
    "        self.features = {}\n",
    "        \n",
    "        self.logReturns = None\n",
    "    \n",
    "    # LOADING PROCESS\n",
    "    # Read file including equity values:\n",
    "    # nb1 Equity;;;;;;;nb2 Equity;;;;;;;...\n",
    "    # Date;PX_LAST;PX_OPEN;PX_HIGH;PX_LOW;PX_VOLUME;;Date...\n",
    "    # Retrieve names\n",
    "    def getStockNames(self):\n",
    "        stockNames = []\n",
    "        with open(self.marketFile) as csvfile:\n",
    "            spamreader = csv.reader(csvfile, delimiter=';')\n",
    "            firstRow = True\n",
    "            for row in spamreader:\n",
    "                if firstRow:\n",
    "                    for i, stockName in enumerate(row):\n",
    "                        if i % 7 == 0:\n",
    "                            toBeAppended = stockName.replace(' Equity','').replace(' ', '')\n",
    "                            stockNames.append(toBeAppended)\n",
    "                    firstRow = not firstRow\n",
    "        print('Stock names loaded')\n",
    "        return(stockNames)\n",
    "    \n",
    "    # Divide in several data frames\n",
    "    # 1 data frame per stock\n",
    "    def getStocks(self):\n",
    "        stocks = {}\n",
    "        i = 0\n",
    "        for index, elt in enumerate(self.stockNames):\n",
    "            tmp = pd.read_csv(filepath_or_buffer=self.marketFile,\n",
    "                              sep=';',\n",
    "                              header=1,\n",
    "                              names=['Date', 'PX_LAST', 'PX_OPEN', 'PX_HIGH', 'PX_LOW', 'PX_VOLUME'],\n",
    "                              usecols=[j for j in range(i, i + 6)],\n",
    "                              low_memory=False).dropna(how='all')\n",
    "            tmp['Date'] = pd.to_datetime(tmp['Date'], format=\"%d/%m/%Y\")\n",
    "            tmp = tmp.set_index(['Date']).ix[:-1]\n",
    "            stocks[elt] = tmp\n",
    "            i += 7\n",
    "        print('Stocks loaded')\n",
    "        return(stocks)\n",
    "    \n",
    "    def joinFeatures(self):\n",
    "        # Concatenate stock frames by index. Pandas figures out which are the missing values, and just fill them next.\n",
    "        features = ['PX_LAST', 'PX_OPEN', 'PX_HIGH', 'PX_LOW', 'PX_VOLUME']\n",
    "        for feature in features:\n",
    "            frames = []\n",
    "            for stockName, stock in self.stocks.iteritems():\n",
    "                frames.append(stock.rename(columns={feature: stockName})[stockName])\n",
    "            self.features[feature] = pd.concat(frames, axis = 1).fillna(method='pad')\n",
    "    \n",
    "    ##### ADDITIONAL FEATURE #####\n",
    "    def addLogReturns(self, feature):\n",
    "        tmp = self.features[feature].pct_change()\n",
    "        self.logReturns =  np.log(1 + tmp)[1:]\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Market loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cac40 = Market(file='../donnees/raw/donnees_CAC.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "globalMarket = Market(file='../donnees/raw/market.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare two markets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "set(cac40.stockNames).difference(set(globalMarket.stockNames).intersection(set(cac40.stockNames)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'LHN', 'NOKIA'}: French stocks that are not in European stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(globalMarket.stockNames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start date formatting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "\n",
    "184 stocks at disposal.\n",
    "\n",
    "Let's find out start and end dates for each stock.\n",
    "\n",
    "Why? Because further modelization requires that stocks we decided to involve have the same trading days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Start dates to know which stock has to be discarded\n",
    "## Data formatting to match Bokeh specs\n",
    "reset_output()\n",
    "\n",
    "startDates = {}\n",
    "for stockName, stock in globalMarket.stocks.iteritems():\n",
    "    startDate = pd.to_datetime(str(stock.index.values[0])).strftime('%Y-%m-%d')\n",
    "    if startDate in startDates: startDates[startDate] += 1\n",
    "    else: startDates[startDate] = 1\n",
    "tmp = {}\n",
    "tmp['dates'] = []\n",
    "tmp['number'] = []\n",
    "for startDate, number in startDates.iteritems():\n",
    "    tmp['dates'].append(startDate)\n",
    "    tmp['number'].append(number)\n",
    "p = Bar(tmp, values='number', label='dates', background_fill_color=\"#E8DDCB\", legend=None)\n",
    "output_notebook()\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# End dates to know which stock has to be discarded\n",
    "endDates = {}\n",
    "for stockName, stock in globalMarket.stocks.iteritems():\n",
    "    endDate = pd.to_datetime(str(stock.index.values[len(stock.index.values)-1])).strftime('%Y-%m-%d')\n",
    "    if endDate in endDates: endDates[endDate] += 1\n",
    "    else: endDates[endDate] = 1\n",
    "endDates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Current stocks are still trading today."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synthesis\n",
    "\n",
    "From both start and end dates results, a rule of thumb is used: stocks starting after 20040101 are discarded, meaning we're getting rid of 18% of the stocks. Data completeness is favored compared to stock completeness => Relevant for next machine learning implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "startDate=datetime(2004, 1, 1)\n",
    "stocksToDiscard=[]\n",
    "for stockName, stock in globalMarket.stocks.iteritems():\n",
    "    if pd.to_datetime(str(stock.index.values[0])) <= startDate: globalMarket.stocks[stockName] = stock[startDate:]\n",
    "    else: stocksToDiscard.append(stockName)\n",
    "for stockToDiscard in stocksToDiscard:\n",
    "    del globalMarket.stocks[stockToDiscard]\n",
    "    globalMarket.stockNames.remove(stockToDiscard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(globalMarket.stockNames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing days handling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "\n",
    "Despite stocks removal, irregularities remain because of trading day specifications in each country.\n",
    "Let's track them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reset_output()\n",
    "\n",
    "lengths = {}\n",
    "for stockName, stock in globalMarket.stocks.iteritems():\n",
    "    if stock.shape[0] not in lengths.keys(): lengths[stock.shape[0]] = 1\n",
    "    else: lengths[stock.shape[0]] += 1\n",
    "\n",
    "tmp = {}\n",
    "tmp['dates'] = []\n",
    "tmp['number'] = []\n",
    "for startDate, number in lengths.iteritems():\n",
    "    tmp['dates'].append(startDate)\n",
    "    tmp['number'].append(number)\n",
    "p = Bar(tmp, values='number', label='dates', background_fill_color=\"#E8DDCB\", legend=None)\n",
    "\n",
    "output_notebook()\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference (i.e who traded the most) seems to be 3201 trading days from 20040101 to 20160629."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synthesis\n",
    "\n",
    "Hypothesis retained: discard a day if one of the stocks did not trade. It is a rough constraint, but it enables not to introduce a bias some days due to holidays in some countries while others are trading normally."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's find out which days are holidays for some countries, not others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stocksPassed = []\n",
    "daysToDiscard = []\n",
    "for stockNameX, stockX in globalMarket.stocks.iteritems():\n",
    "    stocksPassed.append(stockNameX)\n",
    "    for stockNameY, stockY in globalMarket.stocks.iteritems():\n",
    "        if stockNameY not in stocksPassed:\n",
    "            symetricDifference = list(set(stockX.index.values).symmetric_difference(set(stockY.index.values)))\n",
    "            for elt in symetricDifference: daysToDiscard.append(elt)\n",
    "daysToDiscard = list(set(daysToDiscard))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "daysToDiscard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Holidays are clearly identified: e.g. May 1st for French stocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(daysToDiscard)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove bogus days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for stockName, stock in globalMarket.stocks.iteritems():\n",
    "    globalMarket.stocks[stockName] = stock.drop(pd.to_datetime(daysToDiscard), errors='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data frame formatting\n",
    "Split stocks dict into data frames for each feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "globalMarket.joinFeatures()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Append interest variable: log return of PX_LAST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "globalMarket.addLogReturns(feature='PX_LAST')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion and saving\n",
    "In the end, 35 stocks have been discarded. Remaining have been cleaned according to above rules of thumbs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = ['PX_LAST', 'PX_OPEN', 'PX_HIGH', 'PX_LOW', 'PX_VOLUME']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for feature in features: globalMarket.features[feature].to_csv(path_or_buf='../donnees/clean/' + feature + '.csv',\n",
    "                                                               sep=';',\n",
    "                                                               index_label='Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "globalMarket.logReturns.to_csv(path_or_buf='../donnees/clean/RET_PX_LAST.csv',\n",
    "                               sep=';',\n",
    "                               index_label='Date')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
